# Constitution.md fÃ¼r GitHub Speckit
## Detektiv-Agenten-Orchestrator

---

## ğŸ¯ Projektvision

Eine Desktop-GUI-Anwendung, die als "Detektiv-Agenten-Orchestrator" fungiert und groÃŸe Cloud-LLMs (GPT-4o, Claude, Gemini) nutzt, um lokale LLMs (via Ollama/AnythingLLM) systematisch zu "verhÃ¶ren" und ausfÃ¼hrliche, konsistente Antworten zu erzwingen.

**Kernkonzept**: Ein intelligenter Detektiv-Agent (Cloud-LLM) stellt iterativ Fragen an einen "Zeugen" (lokales LLM), analysiert Antworten auf LÃ¼cken und erzwingt VollstÃ¤ndigkeit durch Nachbohren.

---

## ğŸ—ï¸ Architektur-Prinzipien

### 1. Technologie-Stack
- **Frontend**: Electron + React (moderne, plattformÃ¼bergreifende Desktop-App)
- **State Management**: Zustand oder Redux fÃ¼r komplexe Agenten-Orchestrierung
- **API-Layer**: Axios fÃ¼r HTTP-Requests
- **Styling**: Tailwind CSS fÃ¼r schnelle UI-Entwicklung
- **Daten-Persistenz**: LocalStorage + JSON-Files fÃ¼r Konfigurationen
- **Build-System**: TypeScript (strict mode), node-gyp fÃ¼r native Module

### 1.1 Entwicklungsumgebung-Anforderungen

**Windows:**
- **Visual Studio 2022** (â‰¥17.0.0) mit:
  - Workload: "Desktop-Entwicklung mit C++"
  - MSVC v143 x64/x86 Build Tools (Latest)
  - Windows SDK â‰¥10.0.15063.468
- **Node.js**: Version 18.x LTS oder neuer
- **Python**: 3.x (fÃ¼r node-gyp)
- **npm-Konfiguration**: `npm config set msvs_version 2022`

**Detaillierte Setup-Anleitung**: Siehe [SETUP.md](../../SETUP.md)

### 2. API-Integration-Strategie
```
Detektiv-APIs (Cloud):
â”œâ”€â”€ OpenAI API (GPT-4o, GPT-4o-mini)
â”œâ”€â”€ Anthropic API (Claude Sonnet 4.5)
â””â”€â”€ Google Gemini API

Zeugen-APIs (Lokal):
â”œâ”€â”€ Ollama (http://127.0.0.1:11434/v1)
â””â”€â”€ AnythingLLM API (Workspace/RAG-Integration)
```

### 3. Kern-Architektur-Komponenten

```typescript
// Zentrale Module
src/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ DetectiveAgent.ts      // VerhÃ¶r-Logik & Orchestrierung
â”‚   â”œâ”€â”€ WitnessInterface.ts    // Zeugen-LLM-Wrapper
â”‚   â””â”€â”€ AnalysisEngine.ts      // LÃ¼cken- & KonsistenzprÃ¼fung
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ CloudLLMClient.ts      // Unified API-Client (OpenAI, Anthropic, Google)
â”‚   â”œâ”€â”€ OllamaClient.ts        // Ollama-Integration
â”‚   â””â”€â”€ AnythingLLMClient.ts   // AnythingLLM-Workspace-API
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ StrategyInput.tsx  // Hypothesen-Eingabe
â”‚   â”‚   â”œâ”€â”€ InterrogationFlow.tsx  // VerhÃ¶r-Visualisierung
â”‚   â”‚   â””â”€â”€ ConclusionView.tsx     // Audit-Ergebnis
â”‚   â””â”€â”€ store/
â”‚       â””â”€â”€ interrogationStore.ts  // State Management
â””â”€â”€ config/
    â””â”€â”€ ConfigManager.ts       // API-Keys & Einstellungen
```

---

## ğŸ“‹ Requirements-Mapping zu Features

### Phase 1: Minimum Viable Product (MVP)
**Ziel**: Funktionierendes VerhÃ¶r-System mit 1 Cloud-LLM + Ollama

#### Must-Have Features:
1. **CLF-02, CLF-03**: Multi-Schritt-VerhÃ¶r-Loop
   ```typescript
   while (!isInterrogationComplete) {
     question = detective.generateQuestion(context);
     answer = witness.respond(question);
     gaps = detective.analyzeGaps(answer);
     if (gaps.length === 0) break;
   }
   ```

2. **API-01, API-02, API-04**: Basic API-Konfiguration
   - Ein konfigurierbares Cloud-LLM (OpenAI als Start)
   - Ollama-Endpunkt mit Standard `http://127.0.0.1:11434/v1`
   - Modell-Auswahl & Temperatur-Slider

3. **GUI-01, GUI-02**: Minimale UI
   - Textfeld fÃ¼r Aufgabe/Hypothese
   - Einfache Liste fÃ¼r Frage-Antwort-Paare
   - Start/Stop-Button

### Phase 2: VollstÃ¤ndige Feature-Implementierung

#### CLF-Module (Core Logic Features):
- **CLF-01**: Template-System fÃ¼r VerhÃ¶r-Muster
  ```json
  {
    "pattern": "chronological",
    "strategy": "Stelle Fragen in zeitlicher Reihenfolge",
    "gapDetection": ["fehlende Zeitangaben", "LogiklÃ¼cken"]
  }
  ```

- **CLF-04**: Konsistenz-Audit mit Scoring
  ```typescript
  interface AuditResult {
    consistencyScore: number;  // 0-100
    contradictions: string[];
    missingFacts: string[];
    conclusion: string;
  }
  ```

- **CLF-05**: Detektiv-Rollen-Editor
  - Dropdown mit Presets ("Sherlock Holmes", "Columbo", "Miss Marple")
  - Custom System-Prompt-Editor mit Syntax-Highlighting

#### API-Module:
- **API-01**: Multi-API-Manager
  ```typescript
  interface LLMProvider {
    id: string;
    name: string;
    apiKey: string;
    baseUrl?: string;
    models: string[];
  }
  ```

- **API-03**: AnythingLLM Integration
  - Workspace-Auswahl
  - RAG-Query-Option fÃ¼r Zeugen-Antworten

#### GUI-Module:
- **GUI-02**: Interaktive Visualisierung
  - Baumansicht mit expandierbaren Knoten
  - Farbcodierung (GrÃ¼n = VollstÃ¤ndig, Gelb = Nachgebohrt, Rot = Widerspruch)

- **GUI-03**: Audit-Dashboard
  - Konsistenz-Score mit Gauge-Chart
  - Liste der WidersprÃ¼che mit Quellenangabe

- **GUI-04**: Konfigurationsmanagement
  - Import/Export als `.detective.json`
  - Preset-Bibliothek (Community-Strategien)

- **GUI-05**: Error-Handling-System
  - Toast-Notifications fÃ¼r API-Fehler
  - Connection-Status-Indicator (grÃ¼n/rot)
  - Retry-Logik mit Exponential Backoff

---

## ğŸ¨ UI/UX-Prinzipien

### 1. Layout-Struktur
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Config] [API Status ğŸŸ¢] [Save/Load]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Strategie & Hypothese                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ [GroÃŸe Textarea fÃ¼r Eingabe]        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ VerhÃ¶r-Ablauf (Live)   â”‚ Audit-Ergebnisâ”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Q1: ...            â”‚ â”‚ â”‚ Score: 85% â”‚â”‚
â”‚ â”‚  â””â”€A1: ...         â”‚ â”‚ â”‚            â”‚â”‚
â”‚ â”‚    â””â”€Q2: ...       â”‚ â”‚ â”‚ âœ“ Konsist. â”‚â”‚
â”‚ â”‚       â””â”€A2: ...    â”‚ â”‚ â”‚ âš  2 LÃ¼cken â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Interaktionsdesign
- **Progressive Disclosure**: Erweiterte Einstellungen ausblendbar
- **Real-time Feedback**: Spinner wÃ¤hrend API-Calls
- **Keyboard Shortcuts**: `Ctrl+Enter` fÃ¼r Start, `Ctrl+S` fÃ¼r Speichern

---

## ğŸ”§ Technische Spezifikationen

### API-Integration Standards

#### 1. OpenAI-Client
```typescript
async function callOpenAI(prompt: string, config: LLMConfig) {
  const response = await axios.post('https://api.openai.com/v1/chat/completions', {
    model: config.model,
    messages: [{ role: 'user', content: prompt }],
    temperature: config.temperature,
    max_tokens: config.maxTokens
  }, {
    headers: { 'Authorization': `Bearer ${config.apiKey}` }
  });
  return response.data.choices[0].message.content;
}
```

#### 2. Ollama-Client
```typescript
async function callOllama(prompt: string, model: string) {
  const response = await axios.post('http://127.0.0.1:11434/v1/chat/completions', {
    model: model,
    messages: [{ role: 'user', content: prompt }]
  });
  return response.data.choices[0].message.content;
}
```

### VerhÃ¶r-Algorithmus (Pseudocode)

```python
def interrogate(hypothesis: str, witness_model: str):
    context = {"hypothesis": hypothesis, "facts": []}
    max_iterations = 10
    
    for i in range(max_iterations):
        # Detektiv generiert Frage
        question = detective_llm.ask(
            f"Basierend auf {context}, was muss noch geklÃ¤rt werden?"
        )
        
        # Zeuge antwortet
        answer = witness_llm.respond(question)
        context["facts"].append({"q": question, "a": answer})
        
        # LÃ¼cken-Analyse
        gaps = detective_llm.analyze_gaps(answer)
        
        if not gaps:
            break  # VerhÃ¶r abgeschlossen
        
        # Nachbohren
        context["gaps"] = gaps
    
    # Finaler Audit
    return detective_llm.audit(context)
```

---

## ğŸ“¦ LiefergegenstÃ¤nde (Deliverables)

### Sprint 1 (Heute, Sonntag)
1. âœ… Electron-App mit React-Setup
2. âœ… Basis-UI mit Strategie-Input
3. âœ… Ollama-Integration (Test mit lokalem Modell)
4. âœ… OpenAI-API-Integration
5. âœ… Einfacher VerhÃ¶r-Loop (3-5 Iterationen)
6. âœ… README.md mit Setup-Anleitung

### Sprint 2 (NÃ¤chste Woche)
- Multi-API-Support (Anthropic, Gemini)
- Erweiterte LÃ¼cken-Analyse mit NLP-Heuristiken
- Baum-Visualisierung
- Konfigurationsspeicherung

### Sprint 3 (Future)
- AnythingLLM-Workspace-Integration
- Community-Preset-Bibliothek
- Export-Funktion (Markdown-Report)
- Batch-Verarbeitung (mehrere Fragen sequenziell)

---

## ğŸš¦ QualitÃ¤tskriterien

### Code-QualitÃ¤t
- **TypeScript strict mode**: Alle Typen explizit
- **ESLint + Prettier**: Konsistenter Code-Style
- **Unit Tests**: Mindestens 60% Coverage fÃ¼r `agents/` und `api/`

### Performance
- API-Calls mit Timeout (30s Maximum)
- Rate Limiting (max. 10 Requests/Minute zu Cloud-APIs)
- Caching von Ollama-Modell-Listen

### Sicherheit
- API-Keys verschlÃ¼sselt in Electron Store
- Keine Keys in Git-Repository
- Input-Sanitization gegen Prompt Injection

---

## ğŸ“ Entwicklungs-Guidelines

### 1. Git-Workflow
```bash
main (protected)
â”œâ”€â”€ develop
â”‚   â”œâ”€â”€ feature/api-integration
â”‚   â”œâ”€â”€ feature/interrogation-loop
â”‚   â””â”€â”€ feature/ui-visualization
```

### 2. Commit-Konventionen
```
feat: Neue Feature-Implementierung
fix: Bugfix
docs: DokumentationsÃ¤nderungen
refactor: Code-Umstrukturierung ohne FunktionsÃ¤nderung
test: Test-HinzufÃ¼gungen
```

### 3. Code-Review-Checkliste
- [ ] ErfÃ¼llt Anforderung aus Requirements-Tabelle
- [ ] TypeScript-Typen korrekt
- [ ] Error Handling implementiert
- [ ] UI-Feedback vorhanden

---

## ğŸ§ª Test-Szenarien

### Test-Case 1: "Dry Oktober"-Szenario
```
Input: "Fasse das Kapitel Ã¼ber Niacin aus dem PDF zusammen"
Erwartung:
1. Detektiv fragt: "Was ist die Hauptfunktion von Niacin?"
2. Zeuge antwortet kurz: "Energiestoffwechsel"
3. Detektiv erkennt LÃ¼cke: "Keine Details zu Dosierung"
4. Nachfrage: "Welche Dosierungsempfehlungen gibt es?"
5. Iteration bis vollstÃ¤ndige Antwort
```

### Test-Case 2: API-Fehlerbehandlung
```
Szenario: Ollama-Server offline
Erwartung: 
- Roter Status-Indicator
- Toast: "Ollama nicht erreichbar unter 127.0.0.1:11434"
- Button "Retry" erscheint
```

---

## ğŸ“š Ressourcen & Links

### API-Dokumentationen
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Anthropic Claude API](https://docs.anthropic.com/)
- [Ollama API](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [AnythingLLM API](https://docs.anythingllm.com/)

### Entwickler-Tools
- [Electron Forge](https://www.electronforge.io/)
- [React Documentation](https://react.dev/)
- [Tailwind CSS](https://tailwindcss.com/)

---

## âœ¨ Vision fÃ¼r die Zukunft

**Langfristige Ziele**:
1. **Multi-Zeugen-VerhÃ¶re**: Mehrere lokale LLMs parallel befragen und Antworten vergleichen
2. **Lern-Modus**: Detektiv-Agent lernt aus erfolgreichen VerhÃ¶r-Strategien
3. **Plugin-System**: Community kann eigene VerhÃ¶r-Muster als Plugins bereitstellen
4. **Forensische Analyse**: Automatisches Erkennen von WidersprÃ¼chen zwischen verschiedenen Zeugen

---

**Erstellt fÃ¼r**: GitHub Speckit Projekt  
**Ziel**: Schnelle Implementierung mit Claude Code in VS Code  
**Lizenz**: MIT (anpassbar)